namespace XtalOpt {
/**

@page tut-xo XtalOpt Tutorial

<!--@section Contents
  - \ref launch
  - \ref init
    - \ref init-comp
    - \ref init-cell
    - \ref init-iad
    - \ref init-molunit
    - \ref init-randspg
    - \ref init-mitosis
  - \ref opt
    - \ref vasp-opt
    - \ref gulp-opt
    - \ref pwscf-opt
    - \ref castep-opt
    - \ref siesta-opt
  - \ref qisetup
    - \ref remotepbs
    - \ref remotesge
    - \ref remoteslurm
    - \ref remotelsf
    - \ref remotell
    - \ref localqi
  - \ref files
  - \ref search-set
  - \ref begin
  - \ref prog-mon
    - \ref trends
    - \ref avogadro2rpc
  - \ref cli
-->

@section launch Launch XtalOpt
Simply run the "XtalOpt" executable (or in MacOS, open the XtalOpt.app file).

@section init Enter composition and restraints
@image html struct-lim.png
@image latex struct-lim.png width=\textwidth

The interface opens to the "Structure Limits" tab, shown above.

@subsection init-comp Chemical Composition
We will use a 6 formula unit supercell of titanium dioxide for this
tutorial, so enter "Ti1 O2" for the "Empirical Formula".
Under the "Formula Units" we can type 6. If the user wants to search multiple
formula units, they would only have to type in the range, or individual numbers
they wish to search (e.g., 1-6; or 1-2, 4, 6).

@subsection init-cell Cell Parameters
We will assume that we know nothing about the system and use very loose
restraints (however, note that a search is much more effective
if chemically reasonable restraints are used).
Set all cell length minima to 1 angstrom and maxima to 20
angstroms. Constrain the angles to be between 60 and 120 degrees, and
the volume from between 1 and 500 cubic angstroms.
(Note that due to the angle adjustment described in
CPC, 2011, 182, 372-387, 60-120 degrees is
the largest range of cell angles that XtalOpt will generate.)
Furthermore, the volume of the cell can be fixed, so that all cells
generated will have the exact same volume.

@subsection init-iad Interatomic Distances (IAD)
There are now two different kinds of interatomic distances available:
scaled interatomic distances and custom interatomic distances.
If "Use Scaled Interatomic Distances" is checked, the covalent radii of
the elements will be multiplied by the "Scale factor", and any radii below
the "Minimum radius" will be set to the "Minimum Radius." The minimum
interatomic distance, then, between pairs of atoms in this setup is the sum
of their radii. For our example,
check the "Use Scaled Interatomic Distances" checkbox and set "Scale factor"
to 0.40 and "Minimum radius" to 0.25.

Custom interatomic distances is an alternative option. If the
"Use Custom Interatomic Distances" box is checked instead, the user can specify
the minimum interatomic distance between every pair of atom types in the table
below the check box.

Finally, a checkbox labelled "Check IAD Post-Optimization" is also now
available. If this box is checked, the interatomic distances are checked
after the optimization is complete, and if any structures fail the
interatomic distance check, they will be marked as failed structures.

@subsection init-molunit Molecular-Unit Builder
If the user chooses to define specific molecular units, this option will
allow them to do so. Once the chemical composition has been defined, the user
can choose the center and neighbor atoms to be set as single-center molecules.
For example, with the 6 formula unit TiO2, we could set 6 Ti atoms to be the center
of 2 O atoms in a linear geometry. We can also decide what the interatomic distance
between the center and neighboring atoms will be. If there are left over atoms,
they will be placed randomly after the molecular untis are added.

The molecular units are only used in the initial generation.

@subsection init-randspg Random Spacegroup Generator
@image html randspg-dialog.png
@image latex randspg-dialog.png width=\textwidth

With the implementation of RandSpg, the initial generation of structures
can be created by using specific spacegroups (or a variety of spacegroups).
The choice for spacegroups will be limited by the chemical composition and number
of formula units.

Spacegroup constraints can only be used in the initial generation. Molunit and randSpg
cannot be used simultaneously.

For more information on randSpg, see <a href="https://doi.org/10.1016/j.cpc.2016.12.005">
this paper</a>.



@subsection init-mitosis Mitosis
For structures with large unit cells/large number of atoms, one can use "Mitosis"
to increase the local order of the initially generated structures. This will create a small
subcell, then multiply the subcell in each direction to fulfill the stoichiometry
and unit cell size. "# of Divisions" defines how many subcells will be replicated, based upon
the user defined number of "Formula Units",
and the a, b, c determine in which direction the cells are replicated.

@section opt Optimizer setup

XtalOpt currently supports the \ref vasp-opt, \ref gulp-opt, \ref
pwscf-opt, \ref castep-opt, and \ref siesta-opt codes for performing geometry
optimizations. Each is detailed in its own section below.

Be aware that program installation is different, and it is
almost certain that the submit files included with these schemes will
not work on any cluster other than the Zurek group's "parity" cluster
at SUNY Buffalo's Center for Computational Research. It may take some
experimentation to get jobs to submit successfully, and you may need
to contact the system administrators of the cluster for assistance for
information about MPI, executable locations, etc. Perhaps the easiest
method to find the correct submit script is to run some trial submissions
by hand, and then replace the structure/search specific information
with the appropriate keywords once a working script has been
generated.


@subsection vasp-opt VASP
\image html opt-set-vasp.png
\image latex opt-set-vasp.png width=\textwidth

On the next tab, load the optimization scheme by clicking the "Load
Opt Scheme" button and selecting the "samples/vasp-xtalopt.scheme"
file that is distributed with the source code. If you do not have a
copy of the source code, the scheme file can be obtained by clicking
<a href="http://xtalopt.github.io/samples/vasp-xtalopt.scheme">
here</a>.

For more details on optimization schemes, see \ref optschemes.

After loading the optimization scheme, XtalOpt will prompt for the
POTCAR files to use. Select files appropriate for the prompted atom.
XtalOpt will construct the POTCAR files on the local computer, and
then copy them over to the cluster when the calculation is
submitted. It is necessary to have the VASP POTCAR files for each
atomic species located somewhere on the local computer. See the VASP
manual for information on obtaining the POTCAR files.

Take a moment to look through each file for each optimization
step. Notice that the INCAR template includes two user-specified
values, %%user2% and %%user3% for the external pressure and the energy
cutoff, respectively. By entering appropriate values in the "user2:"
and "user3:" fields on the left, it is easy to update these values for
all optimization steps.

Notice the other %%keyword% values in the job.pbs templates. These are
used to enter information that is specific to a search or structure
when the actual input files are written prior to job submission. Click
the "Help" button for a full listing of the available keywords.

XtalOpt expects VASP to use the default filenames, mainly POSCAR,
CONTCAR, and OUTCAR.

\ref qisetup "Skip to next section."

@subsection gulp-opt GULP
\image html opt-set-gulp.png
\image latex opt-set-gulp.png width=\textwidth

On the next tab we choose GULP for the local optimizer and enter a template
for GULP to use. Select "GULP" as the "Optimizer" and
"xtal.gin" as "Template". Next, fill out the text field on the
right with the following template:
\code
opti conj conp
switch_minimiser bfgs gnorm 0.5
cell
  %a% %b% %c% %alphaDeg% %betaDeg% %gammaDeg%
frac
%coordsFrac%
species
Ti 2.196
O -1.098
buck
Ti Ti 31120.1 0.1540 5.25  15
O  O  11782.7 0.2340 30.22 15
Ti O  16957.5 0.1940 12.59 15
lennard 12 6
Ti Ti 1 0 15
O  O  1 0 15
Ti O  1 0 15
\endcode

Alternatively, one can load the scheme file distributed with the
source code under samples/gulp-TiO-xtalopt.scheme. If the source code
is not available, the scheme file can be obtained by clicking <a href="http://xtalopt.github.io/samples/gulp-TiO-xtalopt.scheme">
here</a>.

For more details on optimization schemes, see \ref optschemes.

Note the "%" surrounding various keywords. These will be replaced by
the structure-specific data when the optimizer is invoked for each
structure. Click "Help" to view all of the keywords available. The
number of optimization steps can be modified with the "Add/Resume"
buttons. The "user" fields in the lower left corner allow users to
specify their own keyword/value pairs, which is useful for making
changes to multiple optimization steps at once. We will only be using
one optimization step in this tutorial.

XtalOpt expects GULP to use the following filenames:

\code
gulp < xtal.gin > xtal.got
\endcode

\ref qisetup "Skip to next section."

@subsection pwscf-opt PWscf
\image html opt-set-pwscf.png
\image latex opt-set-pwscf.png width=\textwidth

On the next tab, load the optimization scheme that is distributed with
the source code under the samples/ directory. The scheme that we want
is named "pwscf-xtalopt.scheme". If the source code is not available,
the scheme file can be obtained by clicking the "Original Format" link
at the bottom of the page <a
href="http://xtalopt.github.io/samples/pwscf-xtalopt.scheme">
here</a>.

For more details on optimization schemes, see \ref optschemes.

Each PWscf input file will need to be edited to specify:
 -# The pseudo_dir containing the pseudopotential files on the remote cluster, and
 -# The pseudopotentials for each atom (under ATOMIC_SPECIES)

Take a moment to look through each file for each optimization step.

Notice the %%keyword% values in the job.pbs templates. These are used
to enter information that is specific to a search or structure when
the actual input files are written prior to job submission. Click the
"Help" button for a full listing of the available keywords.

XtalOpt expects PWscf to use the following filenames:

\code
pw.x < xtal.in > xtal.out
\endcode

\ref qisetup "Skip to next section."

@subsection castep-opt CASTEP
\image html opt-set-castep.png
\image latex opt-set-castep.png width=\textwidth

On the next tab, load the optimization scheme that is distributed with
the source code under the samples/ directory. The scheme that we want
is named "castep-xtalopt.scheme". If the source code is not available,
the scheme file can be obtained by clicking the "Original Format" link
at the bottom of the page <a
href="http://xtalopt.github.io/samples/castep-xtalopt.scheme">
here</a>.

For more details on optimization schemes, see \ref optschemes.

It is important to note that CASTEP input files require the "%"
character to define blocks. The percent character is special in the
XtalOpt input template parser to define keywords (see below). To
insert a literal "%" into the input, use %percent%.

E.g. Specification of the fractional coordinate block in the .cell
template should look like:

@code
%block% POSITIONS_FRAC
%coordsFrac%
%endblock% POSITIONS_FRAC
@endcode

Take a moment to look through each file for each optimization step.

Notice the %%keyword% values in the job.pbs templates. These are used
to enter information that is specific to a search or structure when
the actual input files are written prior to job submission. Click the
"Help" button for a full listing of the available keywords.

XtalOpt expects CASTEP to use the following filenames:

\code
# XtalOpt will write xtal.cell, xtal.param
castep xtal
# CASTEP will create xtal.castep
\endcode

\ref qisetup "Skip to next section."

@subsection siesta-opt SIESTA
\image html opt-set-siesta.png
\image latex opt-set-siesta.png width=\textwidth

On the next tab we choose SIESTA for the local optimizer and enter a template for SIESTA to use. Select "SIESTA" as the "Optimizer" and "xtal.fdf" as "Template".

Next, fill out the text field on the right with the following template:

@code
SystemName          %description%-%gen%x%id%
SystemLabel         xtal

NumberOfAtoms       %numAtoms%
NumberOfSpecies     %numSpecies%

%block% ChemicalSpeciesLabel
%chemicalSpeciesLabel%
%endblock% ChemicalSpeciesLabel

%block% PAO.Basis                 # Define Basis set
Ti    5      1.91
 n=3    0    1   E     93.95      5.20
   5.69946662616249
   1.00000000000000
 n=3    1    1   E     95.47      5.20
   5.69941339465994
   1.00000000000000
 n=4    0    2   E     96.47      5.60
   6.09996398975307        5.09944363262274
   1.00000000000000        1.00000000000000
 n=3    2    2   E     46.05      4.95
   5.94327035784617        4.70009988294302
   1.00000000000000        1.00000000000000
 n=4    1    1   E      0.50      1.77
   3.05365979938936
   1.00000000000000
%endblock% PAO.Basis

%block% PAO.BasisSizes
        O      DZP
%endblock% PAO.BasisSizes

XC.functional GGA
XC.authors    PBE

LatticeConstant          1 Ang
%block% LatticeVectors
%cellMatrixAngstrom%
%endblock% LatticeVectors

%block% kgrid_Monkhorst_Pack
   3  0  0  0.5
   0  3  0  0.5
   0  0  3  0.5
%endblock% Kgrid_Monkhorst_Pack

MeshCutoff         100.0 Ry

MaxSCFIterations     1000
DM.MixingWeight      0.05
DM.NumberPulay       3
DM.Tolerance         1.d-4

SolutionMethod       diagon

SpinPolarized   true
LongOutput true

MD.TypeOfRun        cg
MD.NumCGsteps       1000
MD.VariableCell     true
MD.MaxForceTol      0.01 eV/Ang  #0.005 eV/Ang
WriteForces         true
WriteCoorCerius     true
WriteCoorXmol       false
WriteDenchar        true
WriteMullikenPop    1

UseSaveData         true

#Diag.ParallelOverK true

AtomicCoordinatesFormat Fractional
%block% AtomicCoordinatesAndAtomicSpecies
%atomicCoordsAndAtomicSpecies%
%endblock% AtomicCoordinatesAndAtomicSpecies
@endcode

<p>Or load the optimization scheme by clicking the "Load Opt Scheme" button and selecting the "samples/siesta-TiO-xtalopt.scheme" file that is distributed with the source code. If the source code is not available, the scheme file can be obtained by clicking <a href="http://xtalopt.github.io/samples/siesta-TiO-xtalopt.scheme">here</a>.</p>

For more details on optimization schemes, see \ref optschemes.

 <p>After loading the optimization scheme, XtalOpt will prompt for the xtal.psf files to use. Select files appropriate for the prompted atom. XtalOpt will copy the individual files over to each structure directory when the calculation is submitted. See the SIESTA manual for information on obtaining the .psf files.</p>

 <p>Notice the other %%keyword% values in the xtal.fdf templates. These are used to enter information that is specific to a search or structure when the actual input files are written prior to job submission. Click the "Help" button for a full listing of the available keywords.</p>

Note: that in the current implementation XtalOpt uses the Total Final Energy printed in the output to determine the fitness of a structure. If the user would like to use a different thermodynamic quantity for the fitness, please contact the XtalOpt developers.

 <p>XtalOpt expects SIESTA to use the following filenames:</p>

 <pre>siesta < xtal.fdf > xtal.out</pre>


@section qisetup Queue setup

XtalOpt currently supports using the \ref remotepbs "PBS", \ref
remotesge "SGE", \ref remoteslurm "SLURM", \ref remotelsf "LSF", and \ref remotell "LoadLeveler" queuing systems on
remote SSH-accessible clusters, as well as an internal \ref localqi
"local" queue that manages calculations on the user's
workstation. Each queueing interface is detailed in its own section
below.

@subsection remotepbs Using a remote PBS cluster
\image html opt-set-pbs.png
\image latex opt-set-pbs.png width=\textwidth

Select "PBS" from the list of Queues, and then click the "Configure..."
button. A new window will prompt for:
  - host: The hostname of the PBS cluster's head node
  - user: The username used to log into the cluster
  - Working directory (Server): A directory that is readable/writable
      by "user" on the cluster, used when performing optimizations.
  - Working directory (Local): A directory that is readable/writable
      by the current user on the local computer. This is where the
      final structures and resume files are written.
  - Description: Used for the %%description% keyword in input templates.
  - Path to qsub: Where to find the qsub executable on the remote
      cluster. Note that if qsub is in the cluster's $PATH, setting
      this to just 'qsub' will work.
  - Path to qdel: Where to find the qdel executable on the remote
      cluster. Note that if qdel is in the cluster's $PATH, setting
      this to just 'qdel' will work.
  - Path to qstat: Where to find the qstat executable on the remote
      cluster. Note that if qstat is in the cluster's $PATH, setting
      this to just 'qstat' will work.
  - "Clean remote directories when finished": will remove all of the generated files from the cluster. Only the files on the local computer will be kept. If you do not want this to occur, make sure to uncheck this option.

A new template, "job.pbs" is added to the list of available
templates. This is the job submission script for PBS. This script
should roughly follow this design:

@code
#/bin/bash
#PBS -l nodes=1:ppn=8
#PBS -o ../%gen%x%id%-%optstep%.out
#PBS -e ../%gen%x%id%-%optstep%.err
#PBS -N %description%-%gen%x%id%-%optstep%

###Include this for XtalOpt scripts!###
export PBS_O_WORKDIR=%rempath%

# Change to structure's working directory, copy input files to node's scratch dirs:
for node in `cat $PBS_NODEFILE | sort | uniq`; do
rsh $node "cp $PBS_O_WORKDIR/* $PBSTMPDIR/;";
done

# Move to the scratch directory
cd $PBSTMPDIR
echo "running in directory $PBSTMPDIR"

# Set any environment variables needed for the optimizer/MPI here:

# Run optimizer, be sure to use the filenames that XtalOpt expects.
# See the template menu in XtalOpt and the example templates in the
# samples/ directory of the XtalOpt sources.

# Don't forget to clean up after MPI if needed!

// Print files from each node
for node in `cat $PBS_NODEFILE | sort | uniq`; do
echo "$node:"
rsh $node "ls -l $PBSTMPDIR"
done
# Copy back results from master node's scratch directory
cp $PBSTMPDIR/* $PBS_O_WORKDIR/
@endcode

For more details on optimization schemes, see \ref optschemes.

A handy trick for monitoring jobs outside of XtalOpt is to include the
following line in job.pbs:

@code
#PBS -N %description%-%gen%x%id%-%optstep%
@endcode

This will name each job, for example, xtalSearch-3x4-2, where
xtalSearch is a user-specified description of the search, and 3x4-2
means that it is the fourth structure in the third generation running
its second optimization step.

\ref files "Skip to next section."

@subsection remotesge Using a remote SGE cluster
\image html opt-set-sge.png
\image latex opt-set-sge.png width=\textwidth

Select "SGE" from the list of Queues, and then click the "Configure..."
button. A new window will prompt for:
  - host: The hostname of the SGE cluster's head node
  - user: The username used to log into the cluster
  - Working directory (Server): A directory that is readable/writable
      by "user" on the cluster, used when performing optimizations.
  - Working directory (Local): A directory that is readable/writable
      by the current user on the local computer. This is where the
      final structures and resume files are written.
  - Description: Used for the %%description% keyword in input templates.
  - Path to qsub: Where to find the qsub executable on the remote
      cluster. Note that if qsub is in the cluster's $PATH, setting
      this to just 'qsub' will work.
  - Path to qdel: Where to find the qdel executable on the remote
      cluster. Note that if qdel is in the cluster's $PATH, setting
      this to just 'qdel' will work.
  - Path to qstat: Where to find the qstat executable on the remote
      cluster. Note that if qstat is in the cluster's $PATH, setting
      this to just 'qstat' will work.
  - "Clean remote directories when finished": will remove all of the generated files from the cluster. Only the files on the local computer will be kept. If you do not want this to occur, make sure to uncheck this option.

@todo Get template for job.sge scripts

A new template, "job.sge" is added to the list of available
templates. This is the job submission script for SGE. It may take some
experimentation to get jobs to submit successfully, and you may need
to contact the system administrators of the cluster for assistance or information
about MPI, executable locations, etc. Perhaps the easiest method to
find the correct SGE script is to run some trial submissions by hand,
and then replace the structure/search specific information with the
appropriate keywords once a working script has been generated.

For more details on optimization schemes, see \ref optschemes.

\ref files "Skip to next section."

@subsection remoteslurm Using a remote SLURM cluster
\image html opt-set-slurm.png
\image latex opt-set-slurm.png width=\textwidth

Select "SLURM" from the list of Queues, and then click the "Configure..."
button. A new window will prompt for:
  - host: The hostname of the SLURM cluster's head node
  - user: The username used to log into the cluster
  - Working directory (Server): A directory that is readable/writable
      by "user" on the cluster, used when performing optimizations.
  - Working directory (Local): A directory that is readable/writable
      by the current user on the local computer. This is where the
      final structures and resume files are written.
  - Description: Used for the %%description% keyword in input templates.
  - Path to sbatch: Where to find the sbatch executable on the remote
      cluster. Note that if sbatch is in the cluster's $PATH, setting
      this to just 'sbatch' will work.
  - Path to scancel: Where to find the scancel executable on the remote
      cluster. Note that if scancel is in the cluster's $PATH, setting
      this to just 'scancel' will work.
  - Path to squeue: Where to find the squeue executable on the remote
      cluster. Note that if squeue is in the cluster's $PATH, setting
      this to just 'squeue' will work.
  - "Clean remote directories when finished": will remove all of the generated files from the cluster. Only the files on the local computer will be kept. If you do not want this to occur, make sure to uncheck this option.

@todo Get template for job.slurm scripts

A new template, "job.slurm" is added to the list of available
templates. This is the job submission script for SLURM. It may take
some experimentation to get jobs to submit successfully, and you may
need to contact the system administrators of the cluster for assistance or
information about MPI, executable locations, etc. Perhaps the easiest
method to find the correct SLURM script is to run some trial
submissions by hand, and then replace the structure/search specific
information with the appropriate keywords once a working script has
been generated.

For more details on optimization schemes, see \ref optschemes.

\ref files "Skip to next section."

@subsection remotelsf Using a remote LSF cluster
\image html opt-set-lsf.png
\image latex opt-set-lsf.png width=\textwidth

Select "LSF" from the list of Queues, and then click the "Configure..." button. A new window will prompt for:
    - host: The hostname of the LSF cluster's head node
    - user: The username used to log into the cluster
    - Working directory (Server): A directory that is readable/writable by "user" on the cluster, used when performing optimizations.
    - Working directory (Local): A directory that is readable/writable by the current user on the local computer. This is where the final structures and resume files are written.
	- Description: Used for the %description% keyword in input templates.
	- Path to bsub: Where to find the bsub executable on the remote cluster. Note that if bsub is in the cluster's $PATH, setting this to just 'bsub' will work.
	- Path to bkill: Where to find the bkill executable on the remote cluster. Note that if bkill is in the cluster's $PATH, setting this to just 'bkill' will work.
	- Path to bjobs: Where to find the bjobs executable on the remote cluster. Note that if bjobs is in the cluster's $PATH, setting this to just 'bjobs' will work.
    - "Clean remote directories when finished": will remove all of the generated files from the cluster. Only the files on the local computer will be kept. If you do not want this to occur, make sure to uncheck this option.

A new template, "job.lsf" is added to the list of available templates. This is the job submission script for LSF. It may take some experimentation to get jobs to submit successfully, and you may need to contact the system administrators of the cluster for assistance or information about MPI, executable locations, etc. Perhaps the easiest method to find the correct LSF script is to run some trial submissions by hand, and then replace the structure/search specific information with the appropriate keywords once a working script has been generated.

For more details on optimization schemes, see \ref optschemes.

\ref files "Skip to next section."

@subsection remotell Using a remote LoadLeveler cluster
\image html opt-set-ll.png
\image latex opt-set-ll.png width=\textwidth

Select "LoadLeveler" from the list of Queues, and then click the "Configure..." button. A new window will prompt for:
    - host: The hostname of the LoadLeveler cluster's head node
    - user: The username used to log into the cluster
    - Working directory (Server): A directory that is readable/writable by "user" on the cluster, used when performing optimizations.
    - Working directory (Local): A directory that is readable/writable by the current user on the local computer. This is where the final structures and resume files are written.
    - Description: Used for the %description% keyword in input templates.
    - Path to llsubmit: Where to find the llsubmit executable on the remote cluster. Note that if llsubmit is in the cluster's $PATH, setting this to just 'llsubmit' will work.
    - Path to llcancel: Where to find the llcancel executable on the remote cluster. Note that if llcancel is in the cluster's $PATH, setting this to just 'llcancel' will work.
    - Path to llq: Where to find the llq executable on the remote cluster. Note that if llq is in the cluster's $PATH, setting this to just 'llq' will work.
    - "Clean remote directories when finished": will remove all of the generated files from the cluster. Only the files on the local computer will be kept. If you do not want this to occur, make sure to uncheck this option.

A new template, "job.ll" is added to the list of available templates. This is the job submission script for LoadLeveler. It may take some experimentation to get jobs to submit successfully, and you may need to contact the system administrators of the cluster for assistance or information about MPI, executable locations, etc. Perhaps the easiest method to find the correct LoadLeveler script is to run some trial submissions by hand, and then replace the structure/search specific information with the appropriate keywords once a working script has been generated.

For more details on optimization schemes, see \ref optschemes.

\ref files "Skip to next section."

@subsection localqi Running optimizations locally
\image html opt-set-local.png
\image latex opt-set-local.png width=.5\textwidth

Select "Local" from the list of Queues, and then click the configure
button. A new window will prompt for:
   - Local working directory: A directory that is readable/writable by
       the current user on the local computer. This is where the final
       structures and resume files are written.

If the optimizer's executable (vasp, gulp, pw.x, castep, etc) is not
in your system path, you will need to specify the location of the
executable by clicking the "Configure..."  button next to the
optimizer selection menu.

For more details on optimization schemes, see \ref optschemes.

\section files What is written to the local directory?
A directory for each structure is created at

\code
[Local working directory]/<gen#>x<id#>
\endcode

that will contain input, output, and data files specific to each
structure. Two additional files are also written to the local
filesystem:

\code
[Local working directory]/xtalopt.state
\endcode

which contains save/resume information to continue a session that has
been stopped, and

\code
[Local working directory]/results.txt
\endcode

which stores a list of all structures sorted by increasing
enthalpy. The latter file is handy for offline analysis, since there
is no need to open XtalOpt to find the most stable structures of a
previous search.

\section search-set Search Settings
\image html search-set.png
\image latex search-set.png width=\textwidth

In the "Search Settings" tab, most of the default settings should
suffice (See CPC, 2011, 182, 372-387). We arbitrarily set the initial
structures to 20 and the continuous structures to 5, although these
may need to be adjusted based on available resources. We will not
specify initial seeds, but the option to do so exists on this screen.

 It is not necessary to limit the number of running jobs unless
running locally, as the PBS queue on the cluster will manage job
control for us. If running locally, set the job limit no higher than
[number of available processor cores] - 1 (e.g. for a quadcore
processor, allow three jobs to run simultaneously). This allows one
core to remain free for the system to run.

There is now a termination criteria called "Total Number of Structures" that will end the run once a certain number of structures have been produced by XtalOpt.

The tolerances for duplicate matching are also found in this tab. They can be adjusted
at any point in the run and the results.txt file will update with the correct duplicates
found based upon the new tolerances.

\section begin "Begin"
\image html prog-start.png "The ``Progress'' tab immediately after starting a search"
\image latex prog-start.png "The ``Progress'' tab immediately after starting a search" width=\textwidth

XtalOpt has everything it needs to start its search at this point;
click the "Begin" button in the lower right corner of the application
to tell it to start the search algorithm. A progress bar appears as
the random first generation is created. Switch to the "Progress" tab
and 20 entries will appear, all with a status of "Waiting for
Optimization". Click "Refresh" on this tab to begin the local
optimizations. From here, XtalOpt will continue to run without user
input, starting new optimizations and generating new structures until
it is stopped by the user.

\section prog-mon Monitor progress
\image html prog-mon.png "The ``Progress'' tab mid-run"
\image latex prog-mon.png "The ``Progress'' tab mid-run" width=\textwidth

As XtalOpt performs the search, the progress table continuously
updates, providing information about each structure. We see
individuals in various stages of completion: most are optimized (in
blue), structure 2x72 has been automatically marked as a duplicate
(dark green) of structure 1x2 and removed from the breeding pool,
structure 3x4 is currently undergoing a local optimization (light
green), while structure 2x10 is waiting to be optimized (light blue).

Other useful information is displayed about each structure, such as
the time spent in optimization, the optimized enthalpy, the cell
volume, spacegroup, and each structure's ancestry (i.e. parent(s) and
parameters for the genetic operator that generated it). A status bar
on the bottom of the window shows the number of structures that are
optimized, running, and failing at any given time. This information is
visible regardless of which tab is currently being viewed.

After every structure has been optimized, it is checked to see if it
is a super cell by performing a primitive reduction. If the primitive
reduction yields a crystal with fewer atoms than it originally had,
the original crystal is marked as a super cell and a new crystal is
generated that is labelled as a primitive reduction of the original.
This primitive-reduced crystal does not undergo optimization - it is
labelled with the same energy as the original crystal. And, if the
user is searching the formula units of the primitive-reduced crystal,
the primitive-reduced crystal becomes a part of that smaller
formula unit's gene pool.

In addition, every time a new crystal is optimized, if the user is
searching multiple formula units and the crystal is found to be low
in energy, a supercell of the crystal may be generated and be added
to the higher formula unit's gene pool.

An additional feature of the progress table is the ability to
immediately visualize any of the structures in the Avogadro2 main
window (assuming Avogadro2 is open with an Avogadro2 RPC server running
- more info can be found in the \ref avogadro2rpc "Avogadro2
section") -- simply clicking on a row in this table will display the
three-dimensional structure in Avogadro2, where it can be visualized,
modified, or exported. If the user would like to add a bit of
"intelligent design" to the evolutionary process, a structure can be
modified and then resubmitted using a context (right-click) menu from
the progress table. The context menu provides tools to (un)kill a
structure, resubmit for local optimization at an arbitrary
optimization step, or replace a problematic structure with a new,
random individual.

Three additional buttons found near the "Refresh All" button in this tab are also available. The "Print Results File" button generates a run-results.txt file that lists all of the information about each structure in order of generation and structure number (As compared to the results.txt file which ranks the structures). The "Remove Extra Files" button is used for VASP runs. It removes any extraneous files in each local subdirectory in order to reduce disk usage. Files kept are structure.state, POTCAR, CONTCAR, OSZICAR, job.slurm and OUTCAR. Finally, the "Rank All" button ranks all currently optimized structures and exports them to a subdirectory (Ranked) in two forms (depending on the optimizer): POSCAR/.got and .cif. Each can be found in separate directories. (Only works for GULP and VASP runs currently).

To alter a run manually, right-clicking on any of the structures in the Progress tab
will bring up a menu of options. These options include: Killing a structure, restarting a structure, replacing a structure, injecting a seed structure, etc. All of these can be
done mid-run.

\subsection trends View trends
\image html trend-view.png "The ``Plot'' tab mid-run displaying enthalpy vs. volume. Each structure is labeled with its Hermann Mauguin spacegroup symbol."
\image latex trend-view.png "The ``Plot'' tab mid-run displaying enthalpy vs.\ volume. Each structure is labeled with its Hermann Mauguin spacegroup symbol." width=\textwidth

Another visualization and analysis tool available during the search is
the interactive plot. The plot is capable of investigating trends in
the search by plotting a point for each individual using structure
number, generation number, enthalpy, energy, $PV$ enthalpy term,
lattice parameters, or cell volume on either axis. This powerful
feature allows the user to visualize complex relationships present in
the generated structures. E.g., a plot of enthalpy vs.\ structure
number provides an overview of the search's progress. Or, recalling
that H = U + PV, plotting enthalpy vs.\ PV enthalpy term or energy
lends insight into whether the enthalpy (H) is dominated by atomic
interactions (U) or cell parameters (PV). Further information is
available by labeling the points with the individual's spacegroup
number, Hermann Mauguin spacegroup symbol, enthalpy, energy, PV
term, volume, generation, or index number.

A particularly useful plot is that of enthalpy vs.\ cell volume, as
shown above. From this view, we see a general trend that enthalpy
increases with volume (the effect is much more pronounced for systems
at higher pressures), and also that below a certain volume enthalpy
rises sharply. From this data set, we see that there is a cluster of
very low enthalpy structures with cell volumes around 180 cubic
angstroms. Armed with this data, we can update the starting volume on
the Cell Initialization tab mid-run to reflect this new piece of
information that the search has provided us. Many of the other
parameters governing structure generation and algorithm specifics can
be similarly modified during a search without the need to restart the
algorithm.

The plot is also interactive; zooming and panning are possible using
simple mouse controls. Clicking on a structure's point on the plot
will load it in the main Avogadro2 window (assuming Avogadro2 is open
with an Avogadro2 RPC server running - more info in the
\ref avogadro2rpc "Avogadro2 section"), allowing all the same
functionality as described above in \ref prog-mon.

\subsection avogadro2rpc View Crystals in Avogadro2
@image html avogadro2rpc.png
@image latex avogadro2rpc.png width=\textwidth
As of release 11, while an XtalOpt window is open, the user may easily
view the crystals in Avogadro2. As long as an Avogadro2 window is open and
an Avogadro2 Remote Procedure Call (RPC) server is running, when a user
selects crystals in XtalOpt
(either via the plot tab or the progress tab), the structure in the Avogadro2
window will automatically display the crystal the user selected. This allows
for quick and easy visualization when analyzing a run.

\section cli Command Line Interface
As of release 11, there is a command line interface (CLI) available
within XtalOpt. This allows users to choose settings and run searches without
the use of the GUI.

First of all, one can see all of the XtalOpt CLI options by running
"xtalopt --help" from a terminal. This prints all options and a description
of each one.

When performing a CLI run, an input file for XtalOpt is required. An example
which contains detailed explanations of various options can be found <a href="http://xtalopt.github.io/samples/commandLineInterface/xtalopt.in">
here</a>.

A CLI run is begun by entering into the terminal "xtalopt --cli". By default,
XtalOpt will search for an "xtalopt.in" file in the current directory to use
for the input file. If a different input file is desired, the user may
explicitly select an input file with "--input-file <file>".
The vast majority of the options are taken
from the GUI, and more information on these options can be be found in their
respective places in the manual. One difference is that
template files need to be created to for the different templates for
queue interfaces and optimization schemes. These templates use the same
%%keywords% that are used in the GUI, and an example of a GULP template
can be found <a href="http://xtalopt.github.io/samples/commandLineInterface/templates/gulp/gin1">here</a>.

When a CLI run first begins, all of the options set by the user and XtalOpt's
resulting settings will be printed
to the terminal (and to an "xtaloptSettings.log" file in the local working
directory). The user should glance over these printed options
to ensure that they are set correctly.
While a CLI run is in progress, the user is still able to update settings via
a file in their local working directory called "xtalopt-runtime-options.txt".
The settings in the "xtalopt-runtime-options.txt" file are read every iteration
of the event loop. Thus, if a setting is changed in that file, it will quickly
be updated in the program.

In addition, while the CLI run is in progress, job submissions, completions,
and errors will be
reported in the terminal. If one wishes to end the CLI run at any time, they
just need to use "ctrl-C" or whatever their process interruption command is.

One is also able to resume a run via the CLI if they type in
"xtalopt --resume --dir <path/to/resume/dir>". This will check to see if
an "xtalopt.state" file is in the specified directory, and if it is, XtalOpt
will attempt to resume the run.

While a CLI run is in progress (or after any run is finished), the user may
view the enthalpy/energy results via the "results.txt" file in the local
working directory.
They may also generate a plot with the "xtalopt --plot --dir <path/to/dir>"
command. This will immediately display a plot using the same code as that
used to generate the plot tab in a GUI run. Similar to a GUI run, plot axes
and other options may be changed. In addition, if Avogadro2 is open in the
background and an Avogadro2 RPC server is running, XtalOpt will still also set
the structure in the Avogadro2 view to the crystals the user selects.

A note for Linux users: if a window manager is not running on the computer
attempting to use CLI mode, the program may still crash. One solution to get
around this is to add the "-platform offscreen" option to the command line
arguments (this will only work if X11 is installed on the computer). This
requirement will hopefully be removed in the next XtalOpt update.
*/

}
